{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ef64c9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 10-06 14:05:41 _core_ext.py:180] Failed to import from vllm._core_C with ImportError('/u/zluo8/sim2real/ToolRL/.venv/lib/python3.12/site-packages/vllm/_core_C.abi3.so: undefined symbol: _ZN5torch6detail10class_baseC2ERKSsS3_SsRKSt9type_infoS6_')\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Tried to instantiate class '_core_C.ScalarType', but it does not exist! Ensure that it is registered via torch::class_",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msys\u001b[39;00m\n\u001b[32m      3\u001b[39m sys.path.append(\u001b[33m\"\u001b[39m\u001b[33m..\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mverl\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mworkers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mrollout\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mvllm_rollout\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m vLLMRollout\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Replace with your desired model name (from https://huggingface.co/models)\u001b[39;00m\n\u001b[32m      6\u001b[39m model_name = \u001b[33m\"\u001b[39m\u001b[33memrecanacikgoz/Qwen2.5-7B-Instruct-ToolRL-grpo-cold\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/sim2real/ToolRL/zheng/../verl/workers/rollout/vllm_rollout/__init__.py:15\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Copyright 2024 Bytedance Ltd. and/or its affiliates\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# See the License for the specific language governing permissions and\u001b[39;00m\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mvllm_rollout\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m vLLMRollout\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/sim2real/ToolRL/zheng/../verl/workers/rollout/vllm_rollout/vllm_rollout.py:38\u001b[39m\n\u001b[32m     36\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mverl\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtorch_functional\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_eos_mask, pad_sequence_to_length\n\u001b[32m     37\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mverl\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mworkers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mrollout\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbase\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BaseRollout\n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mverl\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mthird_party\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mvllm\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LLM, vllm_version\n\u001b[32m     39\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mverl\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mthird_party\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mvllm\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m parallel_state \u001b[38;5;28;01mas\u001b[39;00m vllm_ps\n\u001b[32m     40\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mvllm\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SamplingParams\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/sim2real/ToolRL/zheng/../verl/third_party/vllm/__init__.py:45\u001b[39m\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m package_version == \u001b[33m'\u001b[39m\u001b[33m0.6.3\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m     44\u001b[39m     vllm_version = \u001b[33m'\u001b[39m\u001b[33m0.6.3\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m45\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mvllm_v_0_6_3\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mllm\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LLM\n\u001b[32m     46\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mvllm_v_0_6_3\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mllm\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LLMEngine\n\u001b[32m     47\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mvllm_v_0_6_3\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m parallel_state\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/sim2real/ToolRL/zheng/../verl/third_party/vllm/vllm_v_0_6_3/llm.py:23\u001b[39m\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PretrainedConfig, PreTrainedTokenizer, PreTrainedTokenizerFast\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mverl\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mworkers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mrollout\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtokenizer\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m HybridEngineBaseTokenizer\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mvllm\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LLM\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mvllm\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01moutputs\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m EmbeddingRequestOutput, RequestOutput\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mvllm\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Counter\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/sim2real/ToolRL/.venv/lib/python3.12/site-packages/vllm/__init__.py:3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[33;03m\"\"\"vLLM: a high-throughput and memory-efficient inference engine for LLMs\"\"\"\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mvllm\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mengine\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01marg_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AsyncEngineArgs, EngineArgs\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mvllm\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mengine\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01masync_llm_engine\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AsyncLLMEngine\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mvllm\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mengine\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mllm_engine\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LLMEngine\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/sim2real/ToolRL/.venv/lib/python3.12/site-packages/vllm/engine/arg_utils.py:11\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mvllm\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01menvs\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01menvs\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mvllm\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconfig\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (CacheConfig, ConfigFormat, DecodingConfig,\n\u001b[32m     12\u001b[39m                          DeviceConfig, EngineConfig, LoadConfig, LoadFormat,\n\u001b[32m     13\u001b[39m                          LoRAConfig, ModelConfig, ObservabilityConfig,\n\u001b[32m     14\u001b[39m                          ParallelConfig, PromptAdapterConfig, SchedulerConfig,\n\u001b[32m     15\u001b[39m                          SpeculativeConfig, TokenizerPoolConfig)\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mvllm\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexecutor\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexecutor_base\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ExecutorBase\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mvllm\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlogger\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m init_logger\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/sim2real/ToolRL/.venv/lib/python3.12/site-packages/vllm/config.py:12\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mvllm\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01menvs\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01menvs\u001b[39;00m\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mvllm\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlogger\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m init_logger\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mvllm\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodel_executor\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlayers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mquantization\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m QUANTIZATION_METHODS\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mvllm\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodel_executor\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodels\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ModelRegistry\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mvllm\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mplatforms\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m current_platform\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/sim2real/ToolRL/.venv/lib/python3.12/site-packages/vllm/model_executor/layers/quantization/__init__.py:3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Dict, Type\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mvllm\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodel_executor\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlayers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mquantization\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01maqlm\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AQLMConfig\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mvllm\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodel_executor\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlayers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mquantization\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mawq\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AWQConfig\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mvllm\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodel_executor\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlayers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mquantization\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mawq_marlin\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AWQMarlinConfig\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/sim2real/ToolRL/.venv/lib/python3.12/site-packages/vllm/model_executor/layers/quantization/aqlm.py:11\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfunctional\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mF\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mparameter\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Parameter\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mvllm\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _custom_ops \u001b[38;5;28;01mas\u001b[39;00m ops\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mvllm\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodel_executor\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlayers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlinear\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LinearBase, LinearMethodBase\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mvllm\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodel_executor\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlayers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mquantization\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbase_config\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     14\u001b[39m     QuantizationConfig)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/sim2real/ToolRL/.venv/lib/python3.12/site-packages/vllm/_custom_ops.py:9\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlibrary\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mvllm\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01menvs\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01menvs\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mvllm\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_core_ext\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ScalarType\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mvllm\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlogger\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m init_logger\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mvllm\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mplatforms\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m current_platform\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/sim2real/ToolRL/.venv/lib/python3.12/site-packages/vllm/_core_ext.py:182\u001b[39m\n\u001b[32m    179\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    180\u001b[39m     logger.warning(\u001b[33m\"\u001b[39m\u001b[33mFailed to import from vllm._core_C with \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[33m\"\u001b[39m, e)\n\u001b[32m--> \u001b[39m\u001b[32m182\u001b[39m ScalarType = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mclasses\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_core_C\u001b[49m\u001b[43m.\u001b[49m\u001b[43mScalarType\u001b[49m\n\u001b[32m    184\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mhasattr\u001b[39m(torch, \u001b[33m\"\u001b[39m\u001b[33m_library\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    185\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(torch._library, \u001b[33m\"\u001b[39m\u001b[33mregister_fake_class\u001b[39m\u001b[33m\"\u001b[39m)):\n\u001b[32m    186\u001b[39m     \u001b[38;5;66;03m# Needed for dynamo support of ScalarType.\u001b[39;00m\n\u001b[32m    187\u001b[39m     \u001b[38;5;129m@torch\u001b[39m._library.register_fake_class(\u001b[33m\"\u001b[39m\u001b[33m_core_C::ScalarType\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    188\u001b[39m     \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mFakeScalarType\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/sim2real/ToolRL/.venv/lib/python3.12/site-packages/torch/_classes.py:13\u001b[39m, in \u001b[36m_ClassNamespace.__getattr__\u001b[39m\u001b[34m(self, attr)\u001b[39m\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__getattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, attr):\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m     proxy = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_C\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_get_custom_class_python_wrapper\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     14\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m proxy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     15\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mClass \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattr\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m not registered!\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mRuntimeError\u001b[39m: Tried to instantiate class '_core_C.ScalarType', but it does not exist! Ensure that it is registered via torch::class_"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModel, AutoTokenizer\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from verl.workers.rollout.vllm_rollout import vLLMRollout\n",
    "# Replace with your desired model name (from https://huggingface.co/models)\n",
    "model_name = \"emrecanacikgoz/Qwen2.5-7B-Instruct-ToolRL-grpo-cold\"\n",
    "\n",
    "# Download tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "# from /u/zluo8/sim2real/ToolRL/verl/trainer/main_ppo.py line 116\n",
    "config = {\n",
    "    'enforce_eager': True,\n",
    "    'free_cache_engine': True,\n",
    "    'prompt_length': 2048,\n",
    "    'response_length': 1024,\n",
    "    'dtype': 'bfloat16',\n",
    "    'gpu_memory_utilization': 0.6,\n",
    "    'load_format': 'dummy_dtensor',\n",
    "}\n",
    "rollout = vLLMRollout(actor_module=model, config=config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8dfbf71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "# Load the Parquet file\n",
    "table = pq.read_table(\"../dataset/rlla_4k/test.parquet\")\n",
    "\n",
    "# Convert to a record batch (like a table of rows)\n",
    "records = table.to_pylist()  # This is a list of dicts, one per row\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "385896ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt:\n",
      " <|im_start|>system\n",
      "You are a helpful multi-turn dialogue assistant capable of leveraging tool calls to solve user tasks and provide structured chat responses.\n",
      "\n",
      "**Available Tools**\n",
      "In your response, you can use the following tools:\n",
      "1. Name: GetPowerBINews\n",
      "Description: Retrieve news related to Power BI.\n",
      "Parameters: {\"page\": {\"description\": \"The page number to retrieve.\", \"type\": \"int\", \"default\": \"\"}}\n",
      "2. Name: SingleOffer\n",
      "Description: API that retrieves information for a single offer from Avito\n",
      "Parameters: {\"singleav\": {\"description\": \"The URL of the Avito offer to retrieve information for\", \"type\": \"string\", \"default\": \"https://www.avito.ma/fr/autre_secteur/maisons_et_villas/Villa_OCP_4_faces_sur_550_metre_de_terrain_49107436.htm\"}}\n",
      "3. Name: Domain WHOIS Lookup API\n",
      "Description: Retrieves WHOIS information for a given domain name.\n",
      "Parameters: {\"domain_name\": {\"description\": \"The domain name for which you would like to retrieve WHOIS details.\", \"type\": \"string\", \"default\": \"\"}}\n",
      "4. Name: GetNews\n",
      "Description: Retrieve Azure news articles\n",
      "Parameters: {\"page\": {\"description\": \"The page number of news articles to retrieve\", \"type\": \"int\", \"default\": \"\"}}\n",
      "\n",
      "**Steps for Each Turn**\n",
      "1. **Think:** Recall relevant context and analyze the current user goal.\n",
      "2. **Decide on Tool Usage:** If a tool is needed, specify the tool and its parameters.\n",
      "3. **Respond Appropriately:** If a response is needed, generate one while maintaining consistency across user queries.\n",
      "\n",
      "**Output Format**\n",
      "```plaintext\n",
      "<think> Your thoughts and reasoning </think>\n",
      "<tool_call>\n",
      "{\"name\": \"Tool name\", \"parameters\": {\"Parameter name\": \"Parameter content\", \"... ...\": \"... ...\"}}\n",
      "{\"name\": \"... ...\", \"parameters\": {\"... ...\": \"... ...\", \"... ...\": \"... ...\"}}\n",
      "...\n",
      "</tool_call>\n",
      "<response> AI's final response </response>\n",
      "```\n",
      "\n",
      "**Important Notes**\n",
      "1. You must always include the `<think>` field to outline your reasoning. Provide at least one of `<tool_call>` or `<response>`. Decide whether to use `<tool_call>` (possibly multiple times), `<response>`, or both.\n",
      "2. You can invoke multiple tool calls simultaneously in the `<tool_call>` fields. Each tool call should be a JSON object with a \"name\" field and an \"parameters\" field containing a dictionary of parameters. If no parameters are needed, leave the \"parameters\" field an empty dictionary.\n",
      "3. Refer to the previous dialogue records in the history, including the user's queries, previous `<tool_call>`, `<response>`, and any tool feedback noted as `<obs>` (if exists).<|im_end|>\n",
      "<|im_start|>user\n",
      "**Dialogue Records History**\n",
      "<user> Hey, I'm looking to stay current on Azure services. Could you fetch the latest news on that topic for me? </user><|im_end|>\n",
      "<|im_start|>assistant\n",
      "\n",
      "Prompt:\n",
      " <|im_start|>system\n",
      "You are a helpful multi-turn dialogue assistant capable of leveraging tool calls to solve user tasks and provide structured chat responses.\n",
      "\n",
      "**Available Tools**\n",
      "In your response, you can use the following tools:\n",
      "1. Name: getSentenceLength\n",
      "Description: Calculate the average length of sentences in a text corpus\n",
      "Parameters: {\"text\": {\"description\": \"The text corpus for which you want to calculate sentence length\", \"type\": \"string\", \"default\": \"\"}}\n",
      "2. Name: lemmatizer\n",
      "Description: Retrieve the base form (lemma) of a given word\n",
      "Parameters: {\"word\": {\"description\": \"The word for which you want to retrieve the lemma\", \"type\": \"string\", \"default\": \"\"}}\n",
      "\n",
      "**Steps for Each Turn**\n",
      "1. **Think:** Recall relevant context and analyze the current user goal.\n",
      "2. **Decide on Tool Usage:** If a tool is needed, specify the tool and its parameters.\n",
      "3. **Respond Appropriately:** If a response is needed, generate one while maintaining consistency across user queries.\n",
      "\n",
      "**Output Format**\n",
      "```plaintext\n",
      "<think> Your thoughts and reasoning </think>\n",
      "<tool_call>\n",
      "{\"name\": \"Tool name\", \"parameters\": {\"Parameter name\": \"Parameter content\", \"... ...\": \"... ...\"}}\n",
      "{\"name\": \"... ...\", \"parameters\": {\"... ...\": \"... ...\", \"... ...\": \"... ...\"}}\n",
      "...\n",
      "</tool_call>\n",
      "<response> AI's final response </response>\n",
      "```\n",
      "\n",
      "**Important Notes**\n",
      "1. You must always include the `<think>` field to outline your reasoning. Provide at least one of `<tool_call>` or `<response>`. Decide whether to use `<tool_call>` (possibly multiple times), `<response>`, or both.\n",
      "2. You can invoke multiple tool calls simultaneously in the `<tool_call>` fields. Each tool call should be a JSON object with a \"name\" field and an \"parameters\" field containing a dictionary of parameters. If no parameters are needed, leave the \"parameters\" field an empty dictionary.\n",
      "3. Refer to the previous dialogue records in the history, including the user's queries, previous `<tool_call>`, `<response>`, and any tool feedback noted as `<obs>` (if exists).<|im_end|>\n",
      "<|im_start|>user\n",
      "**Dialogue Records History**\n",
      "<user> Can you calculate the average sentence length? </user><|im_end|>\n",
      "<|im_start|>assistant\n",
      "\n",
      "Prompt:\n",
      " <|im_start|>system\n",
      "You are a helpful multi-turn dialogue assistant capable of leveraging tool calls to solve user tasks and provide structured chat responses.\n",
      "\n",
      "**Available Tools**\n",
      "In your response, you can use the following tools:\n",
      "1. Name: Verify Email\n",
      "Description: Verifies and normalizes an email address\n",
      "Parameters: {\"email\": {\"description\": \"Email address to be verified and normalized\", \"type\": \"string\", \"default\": \"\"}, \"checkSMTP\": {\"description\": \"Whether to check SMTP connection on port 25\", \"type\": \"boolean\", \"default\": \"false\"}, \"suggestDomain\": {\"description\": \"Whether to suggest a domain for the email address\", \"type\": \"boolean\", \"default\": \"false\"}}\n",
      "2. Name: GetAllPlannerTasksforaUser\n",
      "Description: Retrieves a list of all planner tasks assigned to a specific user in the email domain.\n",
      "Parameters: {\"userName\": {\"description\": \"The username of the user for whom to retrieve planner tasks.\", \"type\": \"string\", \"default\": \"\"}}\n",
      "3. Name: getTestWebhookPayloadBounce\n",
      "Description: Retrieve a test webhook payload for a bounce event.\n",
      "Parameters: {\"email\": {\"description\": \"The email address that triggered the bounce event.\", \"type\": \"string\", \"default\": \"\"}, \"bounceReason\": {\"description\": \"The reason for the bounce event.\", \"type\": \"string\", \"default\": \"\"}}\n",
      "\n",
      "**Steps for Each Turn**\n",
      "1. **Think:** Recall relevant context and analyze the current user goal.\n",
      "2. **Decide on Tool Usage:** If a tool is needed, specify the tool and its parameters.\n",
      "3. **Respond Appropriately:** If a response is needed, generate one while maintaining consistency across user queries.\n",
      "\n",
      "**Output Format**\n",
      "```plaintext\n",
      "<think> Your thoughts and reasoning </think>\n",
      "<tool_call>\n",
      "{\"name\": \"Tool name\", \"parameters\": {\"Parameter name\": \"Parameter content\", \"... ...\": \"... ...\"}}\n",
      "{\"name\": \"... ...\", \"parameters\": {\"... ...\": \"... ...\", \"... ...\": \"... ...\"}}\n",
      "...\n",
      "</tool_call>\n",
      "<response> AI's final response </response>\n",
      "```\n",
      "\n",
      "**Important Notes**\n",
      "1. You must always include the `<think>` field to outline your reasoning. Provide at least one of `<tool_call>` or `<response>`. Decide whether to use `<tool_call>` (possibly multiple times), `<response>`, or both.\n",
      "2. You can invoke multiple tool calls simultaneously in the `<tool_call>` fields. Each tool call should be a JSON object with a \"name\" field and an \"parameters\" field containing a dictionary of parameters. If no parameters are needed, leave the \"parameters\" field an empty dictionary.\n",
      "3. Refer to the previous dialogue records in the history, including the user's queries, previous `<tool_call>`, `<response>`, and any tool feedback noted as `<obs>` (if exists).<|im_end|>\n",
      "<|im_start|>user\n",
      "**Dialogue Records History**\n",
      "<user> Could you verify if the email address example@domain.com is valid? Also, please check if it can receive emails. </user><|im_end|>\n",
      "<|im_start|>assistant\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Model and tokenizer loaded successfully.\")\n",
    "\n",
    "\n",
    "for idx, record in enumerate(records[:3]):  # Display the first 3 records\n",
    "    print(f'----- Record {idx} -----')\n",
    "    prompt = record['prompt']\n",
    "    for p in prompt:\n",
    "        print(\"role: \" + p['role'])\n",
    "        print(\"content:\")\n",
    "        print(p['content'])\n",
    "    # This is from /u/zluo8/sim2real/ToolRL/verl/utils/dataset/rl_dataset.py line 131\n",
    "    prompt = tokenizer.apply_chat_template(prompt, tokenize=False, add_generation_prompt=True)\n",
    "    output = rollout.generate_sequences([prompt])\n",
    "    print(\"Output:\\n\", output[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
